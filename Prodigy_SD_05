import requests
from bs4 import BeautifulSoup
import pandas as pd

def get_page_content(url):
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3"}
    response = requests.get(url, headers=headers)
    response.raise_for_status()  # Check if the request was successful
    return response.content

def extract_product_info(soup):
    products = []
    for product in soup.select('.s-main-slot .s-result-item'):
        name = product.select_one('h2 a span')
        price = product.select_one('.a-price-whole')
        rating = product.select_one('.a-icon-alt')
        
        if name and price and rating:
            products.append({
                'Name': name.text.strip(),
                'Price': price.text.strip(),
                'Rating': rating.text.strip()
            })
    return products

def scrape_products(url):
    print(f"Scraping URL: {url}")
    content = get_page_content(url)
    soup = BeautifulSoup(content, 'html.parser')
    return extract_product_info(soup)

def main():
    url = 'https://www.amazon.com/s?k=laptops'
    products = scrape_products(url)
    
    if products:
        df = pd.DataFrame(products)
        df.to_csv('products.csv', index=False)
        print("Data saved to products.csv")
    else:
        print("No products found or error in scraping.")

if __name__ == "__main__":
    main()
